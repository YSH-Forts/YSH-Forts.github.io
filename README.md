Scrapy Crawl Ten Websites
====  

How to use
-------  

 - cd the directory of spider.py,then run in the terminal by coding
```
scrapy crawl spider
```
for each project there is a run.p.py script, just run it
```
python run.p.py
```

Requirements
-------  

 - spider  ：spider.py
	 *includeing one spider.py,which can crawl ten different websites *
 - pipelines ：pipelines.py
	 *save contents to a csv file*
 - items ：items.py
	*title,url,introduction*
 - settings ：settings.py
